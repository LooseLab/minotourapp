# Program to parse fastq files generated by ont2d
import sys
import os
import time
from watchdog.observers.polling import PollingObserver as Observer
from watchdog.events import FileSystemEventHandler
import re
# import MySQLdb #note problem installing on python 3
import configargparse
import multiprocessing
import platform  # MS
import signal
import threading
from Bio import SeqIO
import numpy as np
import datetime
import dateutil.parser


def parsefastq(fastq, rundict):
    for record in SeqIO.parse(fastq, "fastq"):
        # print(record.id)
        # print(record.seq)
        descriptiondict = parsedescription(record.description)
        if descriptiondict["runid"] not in rundict:
            rundict[descriptiondict["runid"]] = Runcollection(args)
        rundict[descriptiondict["runid"]].add_read(record, descriptiondict)
        # print(record.format("qual"))
        # print(len(record.seq))


def parsedescription(description):
    descriptiondict = dict()
    descriptors = description.split(" ")
    del descriptors[0]
    for item in descriptors:
        bits = item.split("=")
        descriptiondict[bits[0]] = bits[1]
    return descriptiondict


class Runcollection():
    def __init__(self, args):
        self.args = args
        self.readid = dict()
        self.cumulength = 0
        self.readcount = 0
        self.readlengths = list()
        self.timeid = dict()
        self.chandict = list()

    def add_read(self, record, descriptiondict):
        if record.id not in self.readid:
            self.readid[record.id] = dict()
            for item in descriptiondict:
                self.readid[record.id][item] = descriptiondict[item]
            # print self.readid[record.id]
            tm = dateutil.parser.parse(self.readid[record.id]["start_time"])
            # print tm
            tm = tm - datetime.timedelta(minutes=(tm.minute % 1) - 1,
                                         seconds=tm.second,
                                         microseconds=tm.microsecond)
            # print tm
            if tm not in self.timeid.keys():
                self.timeid[tm] = dict()
                self.timeid[tm]["cumulength"] = 0
                self.timeid[tm]["count"] = 0
                self.timeid[tm]["readlengths"] = list()
                self.timeid[tm]["chandict"] = list()

            # This is illustrating how to access the sequence but will be a memory problem
            # self.readid[record.id]["seq"]=record.seq
            # self.readid[record.id]["qual"]=record.format("qual")
            if self.readid[record.id]["ch"] not in self.chandict:
                self.chandict.append(self.readid[record.id]["ch"])

            if self.readid[record.id]["ch"] not in self.timeid[tm]["chandict"]:
                self.timeid[tm]["chandict"].append(self.readid[record.id]["ch"])

            self.readid[record.id]["len"] = len(record.seq)
            self.cumulength += len(record.seq)
            self.timeid[tm]["cumulength"] += len(record.seq)
            self.readcount += 1
            self.timeid[tm]["count"] += 1
            self.readlengths.append(len(record.seq))
            self.timeid[tm]["readlengths"].append(len(record.seq))
            # print(record.id)
            # print(record.seq)
            # print(record.description)
            # print(record.format("qual"))
            # print(len(record.seq))

    def read_count(self):
        return len(self.readid)

    def mean_median_std_max_min(self):
        return np.average(self.readlengths), np.median(self.readlengths), np.std(self.readlengths), np.max(
            self.readlengths), np.min(self.readlengths)

    def parse1minwin(self):
        for time in sorted(self.timeid):
            print(time, self.timeid[time]["cumulength"], np.max(self.timeid[time]["readlengths"]),
                  np.min(self.timeid[time]["readlengths"]), np.average(self.timeid[time]["readlengths"]),
                  self.timeid[time]["count"], len(self.timeid[time]["chandict"]))


def file_dict_of_folder_simple(path):
    file_list_dict = dict()
    # ref_list_dict=dict()
    print("File Dict Of Folder Called")
    counter = 0
    if os.path.isdir(path):
        print("caching existing fastq files in: %s" % (path))
        for path, dirs, files in os.walk(path):
            for f in files:
                # print f
                counter += 1
                print(counter)
                # if (("downloads" in path )):
                # if ("muxscan" not in f and args.callingdir not in path and f.endswith(".fast5") ):
                if (f.endswith(".fastq")):
                    file_list_dict[os.path.join(path, f)] = os.stat(os.path.join(path, f)).st_mtime
                    # try:
                    #    file_descriptor = update_file_descriptor(os.path.join(path, f),file_descriptor)
                    # except:
                    #    pass
    print("processed %s files" % (counter))
    print("found %d existing fast5 files to process first." % (len(file_list_dict)))
    return file_list_dict


class MyHandler(FileSystemEventHandler):
    def __init__(self, args):
        """Collect information about files already in the folders"""
        self.file_descriptor = dict()
        self.args = args
        # adding files to the file_descriptor is really slow - therefore lets skip that and only update the files when we want to basecall thread_number
        # self.creates,self.file_descriptor=file_dict_of_folder(args.watchdir, self.file_descriptor)
        self.creates = file_dict_of_folder_simple(args.watchdir)
        self.processing = dict()
        self.running = True
        self.rundict = dict()
        t = threading.Thread(target=self.processfiles)

        try:
            t.start()
            print("Watchdog started")
        except (KeyboardInterrupt, SystemExit):
            t.stop()

    def lencreates(self):
        return len(self.creates)

    def lenprocessed(self):
        return len(self.processed)

    def processfiles(self):
        everyten = 0
        while self.running:
            print("processfiles running")
            # if not os.path.exists(os.path.join(args.watchdir,args.callingdir)):
            #    os.mkdir(os.path.join(args.watchdir,args.callingdir))
            # print "reads queued:", self.lencreates()
            # print "reads being processed:", self.lenprocessed()
            # print "reads finished:", self.finished
            # print "trackingdict length:", len(self.tracking_dict)
            # print "file_descriptor length:", len(self.file_descriptor)
            # print "albacoremark length:", len(self.albacoremark)
            # print "albacorerunner length:", len(self.albacorerunner)
            # print "albacoredone length:", len(self.albacoredone)
            # print "joblist length:",len(self.joblist)


            countingtime = 0
            # print "running"
            for fastqfile, createtime in sorted(self.creates.items(), key=lambda x: x[1]):
                delaytime = 0
                if (int(
                        createtime) + delaytime < time.time()):  # file created 5 sec ago, so should be complete. For simulations we make the time longer.
                    print(fastqfile)
                    del self.creates[fastqfile]
                    parsefastq(fastqfile, self.rundict)

            for runid in self.rundict:
                print("RunID", runid)
                print("Read Number:", self.rundict[runid].readcount, "Total Length:", self.rundict[runid].cumulength,
                      "Average Length", self.rundict[runid].cumulength / self.rundict[runid].readcount, "Chan Count",
                      len(self.rundict[runid].chandict))
                (mean, median, std, maxval, minval) = self.rundict[runid].mean_median_std_max_min()
                print("mean", mean, "median", median, "std", std, "max", maxval, "min", minval)
                # print self.rundict[runid].timeid
                self.rundict[runid].parse1minwin()

            time.sleep(5)

    def on_created(self, event):
        """Watchdog counts a new file in a folder it is watching as a new file"""
        """This will add a file which is added to the watchfolder to the creates and the info file."""
        if (event.src_path.endswith(".fastq")):
            # print "seen a file", event.src_path
            self.creates[event.src_path] = time.time()
            # elif ("albacore" in event.src_path and args.callingdir not in event.src_path and args.finishdir not in event.src_path and event.src_path.endswith(".fast5")):
            #    self.albacorefiles[event.src_path] = time.time()
            #    print "seen an albacore file created"

            # self.total[event.src_path] = time.time()

    def on_modified(self, event):
        if (event.src_path.endswith(".fastq")):
            # print "seen a file", event.src_path
            self.creates[event.src_path] = time.time()

    def on_moved(self, event):
        """Watchdog considers a file which is moved within its domain to be a move"""
        """When a file is moved, we just want to update its location in the master dictionary."""
        # print "On Moved Called"
        if (event.dest_path.endswith(".fastq")):
            print("seen a fastq file move")
            # print getfilename(event.src_path), event.src_path,event.dest_path
            # try:
            # self.creates[event.dest_path] = self.creates[event.src_path]
            # del self.creates[event.src_path]
            # print "file finished basecalling:", getfilename(event.dest_path)
            #    self.albacoredone[event.dest_path] = time.time()
            # del self.albacorefiles[event.src_path]
            # del self.creates[event.src_path]
            # except Exception as e:
            #    print "Error deleting file:",e
            #    pass
            # else:
            # print "seen a file move"
            # print getfilename(event.src_path), event.src_path,event.dest_path
            # print self.creates
            # del self.creates[]

    def on_deleted(self, event):
        print("On Deleted Called", event.src_path)
        # if event.src_path in self.creates.keys():
        #     del self.creates[event.src_path]
        # """ We need to clean out any other references to these files"""
        # if getfilename(event.src_path) in self.processing.keys():
        #     del self.processing[getfilename(event.src_path)]
        # if getfilename(event.src_path) in self.processed.keys():
        #     del self.processed[getfilename(event.src_path)]


if __name__ == '__main__':

    global OPER

    OPER = platform.system()
    if OPER is 'Windows':  # MS
        OPER = 'windows'
    else:
        OPER = 'linux'  # MS
    print(OPER)  # MS

    if OPER is 'linux':
        config_file = os.path.join(os.path.sep, \
                                   os.path.dirname(os.path.realpath('__file__' \
                                                                    )), 'minfq_posix.config')

    if OPER is 'windows':
        config_file = os.path.join(os.path.sep, sys.prefix,
                                   'minfq_windows.config')

    parser = \
        configargparse.ArgParser(description='minFQ: A program to analyse minION fastq files in real-time or post-run.' \
                                 , default_config_files=[config_file])
    parser.add(
        '-w',
        '--watch-dir',
        type=str,
        required=True,
        default=None,
        help='The path to the folder containing the downloads directory with fast5 reads to analyse - e.g. C:\\data\\minion\\downloads (for windows).',
        dest='watchdir'
    )

    args = parser.parse_args()

    print(args.watchdir)

    event_handler = MyHandler(args)
    observer = Observer()
    observer.schedule(event_handler, path=args.watchdir, recursive=True)
    observer.daemon = True
    try:
        observer.start()
        while 1:
            time.sleep(1)
    except (KeyboardInterrupt, SystemExit):
        print("catching a ctrl-c event")
        # my_client.stop()
        observer.stop()
        observer.join()
        # die_nicely(oper)
